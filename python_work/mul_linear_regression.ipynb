{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26c52982-0619-484e-8c16-4c3b4b627075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data.ndim= 2 , x_data.shape= (25, 3)\n",
      "t_data.ndim= 2 , t_data.shape= (25, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "loaded_data=np.loadtxt('data/data-01-test-score.csv',delimiter=',',dtype=np.float32)\n",
    "\n",
    "x_data=loaded_data[:,0:-1]\n",
    "t_data=loaded_data[:,[-1]]\n",
    "\n",
    "#print(x_data)\n",
    "#print(t_data)\n",
    "print('x_data.ndim=',x_data.ndim,', x_data.shape=',x_data.shape)\n",
    "print('t_data.ndim=',t_data.ndim,', t_data.shape=',t_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f51bc40-b13f-4ca9-a181-5f5af51f387f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W= [[0.67027226]\n",
      " [0.29005836]\n",
      " [0.85262627]] , W.shape= (3, 1) ,b= [0.29441271] , b.shape= (1,)\n"
     ]
    }
   ],
   "source": [
    "W=np.random.rand(3,1)\n",
    "b=np.random.rand(1)\n",
    "print('W=',W,', W.shape=',W.shape,',b=',b,', b.shape=',b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db65bd27-ecd4-4a0a-a860-0c7e71f44206",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(x,t):\n",
    "    y=np.dot(x,W)+b\n",
    "    \n",
    "    return(np.sum((t-y)**2))/(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ec6f5b1-9b2a-48a7-97f8-2e9113c9b562",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_derivative(f,x):\n",
    "    delta_x=1e-4\n",
    "    grad=np.zeros_like(x)\n",
    "    #print(\"debug1. initial input variable =\",x)\n",
    "    #print(\"debug2. initial grad =\",grad)\n",
    "    #print(\"==============================================\")\n",
    "    \n",
    "    it=np.nditer(x,flags=['multi_index'],op_flags=['readwrite'])\n",
    "    \n",
    "    while not it.finished:\n",
    "        idx=it.multi_index\n",
    "        #print(\"debug3. idx= \", idx, \", x[idx] =\",x[idx])\n",
    "        \n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val) + delta_x\n",
    "        fx1 = f(x) # f(x+delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val - delta_x\n",
    "        fx2 = f(x) # f(x-delta_x)\n",
    "        grad[idx] = (fx1 - fx2) / (2*delta_x)\n",
    "        \n",
    "        #print(\"debug4. grad[idx] =\",grad[idx])\n",
    "        #print(\"debug5. grad =\",grad)\n",
    "        #print(\"==============================================\")\n",
    "        \n",
    "        x[idx] = tmp_val\n",
    "        it.iternext() \n",
    "        \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7bfb94c-77ec-491e-8bd6-e31a359b5c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_val(x,t):\n",
    "    y=np.dot(x,W)+b\n",
    "    return (np.sum((t-y)**2))/(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab025ec3-ec7a-42c8-939a-b59aafe66f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#학습을 마친 후, 임의 데이터에 대해 미래 값 예측 함수\n",
    "def predict(x):\n",
    "    y=np.dot(x,W)+b\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a9cd7889-c232-4374-8112-f845876f276c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial error value= 6.144861256832244 Initial W= [[0.35754283]\n",
      " [0.52880101]\n",
      " [1.12396962]] \n",
      " ,b= [0.25813692]\n",
      "step= 0 , error value= 6.14486092046643 , W= [[0.35754244]\n",
      " [0.52880122]\n",
      " [1.12396981]] , b= [0.25813515]\n",
      "step= 400 , error value= 6.144727236373911 , W= [[0.3573945 ]\n",
      " [0.52888134]\n",
      " [1.12404381]] , b= [0.25742738]\n",
      "step= 800 , error value= 6.144595065699118 , W= [[0.35726064]\n",
      " [0.52895405]\n",
      " [1.12411139]] , b= [0.25671964]\n",
      "step= 1200 , error value= 6.144464141232707 , W= [[0.3571395 ]\n",
      " [0.52902005]\n",
      " [1.12417314]] , b= [0.25601193]\n",
      "step= 1600 , error value= 6.144334244178663 , W= [[0.35702989]\n",
      " [0.52907997]\n",
      " [1.12422963]] , b= [0.25530427]\n",
      "step= 2000 , error value= 6.144205195382271 , W= [[0.3569307 ]\n",
      " [0.52913439]\n",
      " [1.12428137]] , b= [0.25459665]\n",
      "step= 2400 , error value= 6.144076848147417 , W= [[0.35684095]\n",
      " [0.52918383]\n",
      " [1.1243288 ]] , b= [0.25388909]\n",
      "step= 2800 , error value= 6.143949082355594 , W= [[0.35675974]\n",
      " [0.52922877]\n",
      " [1.12437234]] , b= [0.25318159]\n",
      "step= 3200 , error value= 6.14382179965012 , W= [[0.35668625]\n",
      " [0.52926962]\n",
      " [1.12441235]] , b= [0.25247416]\n",
      "step= 3600 , error value= 6.14369491949331 , W= [[0.35661975]\n",
      " [0.52930679]\n",
      " [1.12444918]] , b= [0.25176679]\n",
      "step= 4000 , error value= 6.143568375937799 , W= [[0.35655957]\n",
      " [0.52934061]\n",
      " [1.12448313]] , b= [0.2510595]\n",
      "step= 4400 , error value= 6.143442114982928 , W= [[0.35650512]\n",
      " [0.52937141]\n",
      " [1.12451447]] , b= [0.25035228]\n",
      "step= 4800 , error value= 6.143316092410155 , W= [[0.35645585]\n",
      " [0.52939947]\n",
      " [1.12454345]] , b= [0.24964515]\n",
      "step= 5200 , error value= 6.1431902720106395 , W= [[0.35641126]\n",
      " [0.52942505]\n",
      " [1.1245703 ]] , b= [0.24893809]\n",
      "step= 5600 , error value= 6.143064624134062 , W= [[0.35637091]\n",
      " [0.52944839]\n",
      " [1.12459522]] , b= [0.24823112]\n",
      "step= 6000 , error value= 6.142939124500122 , W= [[0.3563344 ]\n",
      " [0.5294697 ]\n",
      " [1.12461839]] , b= [0.24752424]\n",
      "step= 6400 , error value= 6.142813753225738 , W= [[0.35630136]\n",
      " [0.52948917]\n",
      " [1.12463998]] , b= [0.24681744]\n",
      "step= 6800 , error value= 6.142688494028217 , W= [[0.35627147]\n",
      " [0.52950698]\n",
      " [1.12466014]] , b= [0.24611074]\n",
      "step= 7200 , error value= 6.142563333572897 , W= [[0.35624441]\n",
      " [0.52952329]\n",
      " [1.124679  ]] , b= [0.24540413]\n",
      "step= 7600 , error value= 6.142438260939107 , W= [[0.35621993]\n",
      " [0.52953823]\n",
      " [1.1246967 ]] , b= [0.24469762]\n",
      "step= 8000 , error value= 6.142313267182697 , W= [[0.35619778]\n",
      " [0.52955194]\n",
      " [1.12471333]] , b= [0.2439912]\n",
      "step= 8400 , error value= 6.142188344977905 , W= [[0.35617774]\n",
      " [0.52956454]\n",
      " [1.12472901]] , b= [0.24328487]\n",
      "step= 8800 , error value= 6.142063488324201 , W= [[0.3561596 ]\n",
      " [0.52957612]\n",
      " [1.12474382]] , b= [0.24257865]\n",
      "step= 9200 , error value= 6.141938692306047 , W= [[0.35614318]\n",
      " [0.5295868 ]\n",
      " [1.12475785]] , b= [0.24187252]\n",
      "step= 9600 , error value= 6.1418139528964595 , W= [[0.35612833]\n",
      " [0.52959664]\n",
      " [1.12477116]] , b= [0.2411665]\n",
      "step= 10000 , error value= 6.141689266795989 , W= [[0.35611488]\n",
      " [0.52960574]\n",
      " [1.12478384]] , b= [0.24046057]\n",
      "step= 10400 , error value= 6.141564631300712 , W= [[0.35610272]\n",
      " [0.52961417]\n",
      " [1.12479593]] , b= [0.23975475]\n",
      "step= 10800 , error value= 6.141440044194611 , W= [[0.35609171]\n",
      " [0.52962197]\n",
      " [1.12480749]] , b= [0.23904903]\n",
      "step= 11200 , error value= 6.141315503660917 , W= [[0.35608175]\n",
      " [0.52962923]\n",
      " [1.12481858]] , b= [0.23834341]\n",
      "step= 11600 , error value= 6.141191008210083 , W= [[0.35607273]\n",
      " [0.52963598]\n",
      " [1.12482924]] , b= [0.2376379]\n",
      "step= 12000 , error value= 6.141066556620051 , W= [[0.35606458]\n",
      " [0.52964228]\n",
      " [1.12483951]] , b= [0.23693248]\n",
      "step= 12400 , error value= 6.140942147888211 , W= [[0.35605719]\n",
      " [0.52964817]\n",
      " [1.12484942]] , b= [0.23622718]\n",
      "step= 12800 , error value= 6.140817781191459 , W= [[0.35605051]\n",
      " [0.52965368]\n",
      " [1.12485902]] , b= [0.23552198]\n",
      "step= 13200 , error value= 6.140693455853619 , W= [[0.35604447]\n",
      " [0.52965886]\n",
      " [1.12486832]] , b= [0.23481688]\n",
      "step= 13600 , error value= 6.140569171318955 , W= [[0.35603899]\n",
      " [0.52966374]\n",
      " [1.12487737]] , b= [0.23411189]\n",
      "step= 14000 , error value= 6.140444927130191 , W= [[0.35603404]\n",
      " [0.52966834]\n",
      " [1.12488617]] , b= [0.233407]\n",
      "step= 14400 , error value= 6.1403207229109045 , W= [[0.35602956]\n",
      " [0.52967269]\n",
      " [1.12489476]] , b= [0.23270222]\n",
      "step= 14800 , error value= 6.14019655835056 , W= [[0.3560255 ]\n",
      " [0.52967681]\n",
      " [1.12490316]] , b= [0.23199755]\n",
      "step= 15200 , error value= 6.140072433192915 , W= [[0.35602183]\n",
      " [0.52968073]\n",
      " [1.12491138]] , b= [0.23129298]\n",
      "step= 15600 , error value= 6.139948347225932 , W= [[0.35601851]\n",
      " [0.52968446]\n",
      " [1.12491945]] , b= [0.23058852]\n",
      "step= 16000 , error value= 6.13982430027385 , W= [[0.3560155 ]\n",
      " [0.52968803]\n",
      " [1.12492737]] , b= [0.22988417]\n",
      "step= 16400 , error value= 6.13970029219061 , W= [[0.35601278]\n",
      " [0.52969144]\n",
      " [1.12493515]] , b= [0.22917993]\n",
      "step= 16800 , error value= 6.139576322854559 , W= [[0.35601032]\n",
      " [0.52969472]\n",
      " [1.12494282]] , b= [0.22847579]\n",
      "step= 17200 , error value= 6.1394523921638475 , W= [[0.35600808]\n",
      " [0.52969788]\n",
      " [1.12495039]] , b= [0.22777176]\n",
      "step= 17600 , error value= 6.139328500033005 , W= [[0.35600607]\n",
      " [0.52970092]\n",
      " [1.12495785]] , b= [0.22706783]\n",
      "step= 18000 , error value= 6.139204646389918 , W= [[0.35600424]\n",
      " [0.52970386]\n",
      " [1.12496523]] , b= [0.22636401]\n",
      "step= 18400 , error value= 6.139080831173377 , W= [[0.35600258]\n",
      " [0.52970671]\n",
      " [1.12497253]] , b= [0.22566031]\n",
      "step= 18800 , error value= 6.13895705433113 , W= [[0.35600109]\n",
      " [0.52970947]\n",
      " [1.12497975]] , b= [0.2249567]\n",
      "step= 19200 , error value= 6.138833315818301 , W= [[0.35599973]\n",
      " [0.52971216]\n",
      " [1.12498691]] , b= [0.22425321]\n",
      "step= 19600 , error value= 6.138709615595968 , W= [[0.3559985 ]\n",
      " [0.52971478]\n",
      " [1.12499402]] , b= [0.22354982]\n",
      "step= 20000 , error value= 6.138585953630166 , W= [[0.35599739]\n",
      " [0.52971734]\n",
      " [1.12500106]] , b= [0.22284655]\n"
     ]
    }
   ],
   "source": [
    "#learning_rate=1e-2 #발산하는 경우, 1e-3 ~ 1e-6 등으로 바꿔서 실행\n",
    "learning_rate=1e-5\n",
    "\n",
    "f=lambda x : loss_func(x_data,t_data) #f(x)=loss_funcs(x_data,t_data)\n",
    "\n",
    "print('Initial error value=',error_val(x_data,t_data),'Initial W=',W,'\\n',',b=',b)\n",
    "\n",
    "for step in range(20001):\n",
    "    W-=learning_rate*numerical_derivative(f,W)\n",
    "    b-=learning_rate*numerical_derivative(f,b)\n",
    "    \n",
    "    if(step%400==0):\n",
    "        print('step=',step,', error value=',error_val(x_data,t_data),', W=',W,', b=',b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "65dbc5c3-61cd-4220-a536-188a247f23db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([178.85997125])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data=np.array([100,98,81])\n",
    "\n",
    "predict(test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
