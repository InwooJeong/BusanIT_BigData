{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d6cf883-0f9d-4fea-bf7f-e294d01dac3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_derivative(f,x):\n",
    "    delta_x = 1e-4\n",
    "    return (f(x+delta_x)-f(x-delta_x))/(2*delta_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e2ac3b5-5eb2-416e-8e7f-8c1ef3360e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_func1(x):\n",
    "    return x**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d182bba7-a592-4804-9193-39b1773021bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result == 6.000000000012662\n"
     ]
    }
   ],
   "source": [
    "result=numerical_derivative(my_func1,3)\n",
    "print(\"result ==\",result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35b582c6-7d9c-46b6-bbf4-d6b282661caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def my_func2(x):\n",
    "    return 3*x*(np.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b3ba11f-8fbf-4d55-92ca-31b724323a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result == 66.50150507518049\n"
     ]
    }
   ],
   "source": [
    "result=numerical_derivative(my_func2,2)\n",
    "print(\"result ==\",result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fc52463-7670-48d7-b516-0904ca992d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3*exp(2)+3*2*exp(2)==66.50150489037586\n"
     ]
    }
   ],
   "source": [
    "print(\"3*exp(2)+3*2*exp(2)==\",end='')\n",
    "print(3*np.exp(2)+3*2*np.exp(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4c99b5c-062c-448c-b287-4e1ab6d3bbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_func3(x):\n",
    "    return 3*x**2+2*x+1  #6x+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee230155-2317-4eb7-a131-1ccd4bcc4b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result == 14.000000000020663\n"
     ]
    }
   ],
   "source": [
    "result=numerical_derivative(my_func3,2)\n",
    "print(\"result ==\",result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9a93da9b-54ce-4a25-82c1-09dd57afdad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def numerical_derivative(f,x):\n",
    "    delta_x=1e-4\n",
    "    grad=np.zeros_like(x)\n",
    "    print(\"debug1. initial input variable =\",x)\n",
    "    print(\"debug2. initial grad =\",grad)\n",
    "    print(\"==============================================\")\n",
    "    \n",
    "    it=np.nditer(x,flags=['multi_index'],op_flags=['readwrite'])\n",
    "    \n",
    "    while not it.finished:\n",
    "        idx=it.multi_index\n",
    "        print(\"debug3. idx= \", idx, \", x[idx] =\",x[idx])\n",
    "        \n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val) + delta_x\n",
    "        fx1 = f(x) # f(x+delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val - delta_x\n",
    "        fx2 = f(x) # f(x-delta_x)\n",
    "        grad[idx] = (fx1 - fx2) / (2*delta_x)\n",
    "        \n",
    "        print(\"debug4. grad[idx] =\",grad[idx])\n",
    "        print(\"debug5. grad =\",grad)\n",
    "        print(\"==============================================\")\n",
    "        \n",
    "        x[idx] = tmp_val\n",
    "        it.iternext() \n",
    "        \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c153283b-8806-4fe0-b420-b74c41e8142d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debug1. initial input variable = [3.]\n",
      "debug2. initial grad = [0.]\n",
      "==============================================\n",
      "debug3. idx=  (0,) , x[idx] = 3.0\n",
      "debug . grad[idx] = 6.000000000012662\n",
      "debug5. grad = [6.]\n",
      "==============================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([6.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def func1(input_obj):\n",
    "    x=input_obj[0]\n",
    "    return x**2\n",
    "\n",
    "numerical_derivative(func1,np.array([3.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3a086437-204e-41e6-be0b-f536d7d15b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debug1. initial input variable = [1. 2.]\n",
      "debug2. initial grad = [0. 0.]\n",
      "==============================================\n",
      "debug3. idx=  (0,) , x[idx] = 1.0\n",
      "debug4. grad[idx] = 7.999999999990237\n",
      "debug5. grad = [8. 0.]\n",
      "==============================================\n",
      "debug3. idx=  (1,) , x[idx] = 2.0\n",
      "debug4. grad[idx] = 15.000000010019221\n",
      "debug5. grad = [ 8.         15.00000001]\n",
      "==============================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 8.        , 15.00000001])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2x+3xy+y^3\n",
    "def func2(input_obj):\n",
    "    x=input_obj[0]\n",
    "    y=input_obj[1]\n",
    "    return (2*x+3*x*y+np.power(y,3))\n",
    "\n",
    "input=np.array([1.0,2.0])\n",
    "\n",
    "numerical_derivative(func2,input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e4a86830-1d2a-4a98-a736-d90ee5b10073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debug1. initial input variable = [[1. 2.]\n",
      " [3. 4.]]\n",
      "debug2. initial grad = [[0. 0.]\n",
      " [0. 0.]]\n",
      "==============================================\n",
      "debug3. idx=  (0, 0) , x[idx] = 1.0\n",
      "debug4. grad[idx] = 6.999999999948159\n",
      "debug5. grad = [[7. 0.]\n",
      " [0. 0.]]\n",
      "==============================================\n",
      "debug3. idx=  (0, 1) , x[idx] = 2.0\n",
      "debug4. grad[idx] = 12.000000000043087\n",
      "debug5. grad = [[ 7. 12.]\n",
      " [ 0.  0.]]\n",
      "==============================================\n",
      "debug3. idx=  (1, 0) , x[idx] = 3.0\n",
      "debug4. grad[idx] = 32.00000000006753\n",
      "debug5. grad = [[ 7. 12.]\n",
      " [32.  0.]]\n",
      "==============================================\n",
      "debug3. idx=  (1, 1) , x[idx] = 4.0\n",
      "debug4. grad[idx] = 15.99999999996271\n",
      "debug5. grad = [[ 7. 12.]\n",
      " [32. 16.]]\n",
      "==============================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 7., 12.],\n",
       "       [32., 16.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#wx+xyz+3w+zy^2\n",
    "def func3(input_obj):\n",
    "    w=input_obj[0,0]\n",
    "    x=input_obj[0,1]\n",
    "    y=input_obj[1,0]\n",
    "    z=input_obj[1,1]\n",
    "    return (w*z+x*y*z+3*w+z*np.power(y,2))\n",
    "\n",
    "#입력을 2X2 godfuffh rntjd\n",
    "input=np.array([[1.0,2.0],[3.0,4.0]])\n",
    "\n",
    "numerical_derivative(func3,input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5599992d-7954-4e77-a16d-b040f1127901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data.shpae= (6, 1) , t_data.shape= (6, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#x_data = np.array([1,2,3,4,5]).reshape(5,1) #W=1, b=1, y=Wx+1\n",
    "#t_data = np.array([2,3,4,5,6]).reshape(5,1)\n",
    "\n",
    "x_data=np.array([9,14,21,27,32,37]).reshape(6,1)\n",
    "t_data=np.array([74,81,86,90,88,92]).reshape(6,1)\n",
    "\n",
    "#raw_data [[1,2],[2,3],[3,4],[4,5],[5,6]]\n",
    "print('x_data.shpae=',x_data.shape,', t_data.shape=',t_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "09287e55-1d2d-425d-abba-93fe127f8426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W= [[0.81084396]] , W.shape= (1, 1) , b= [0.0479357] , b.shape= (1,)\n"
     ]
    }
   ],
   "source": [
    "W=np.random.rand(1,1)\n",
    "b=np.random.rand(1)\n",
    "print('W=',W,', W.shape=',W.shape,', b=',b,', b.shape=',b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6ce85d7c-c509-4c95-a2de-1519ab3da766",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(x,t):\n",
    "    y=np.dot(x,W)+b\n",
    "    return (np.sum((t-y)**2))/(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ec37953e-0370-4a25-abc1-17ee98d21bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_derivative(f,x):\n",
    "    delta_x=1e-4\n",
    "    grad=np.zeros_like(x)\n",
    "    #print(\"debug1. initial input variable =\",x)\n",
    "    #print(\"debug2. initial grad =\",grad)\n",
    "    #print(\"==============================================\")\n",
    "    \n",
    "    it=np.nditer(x,flags=['multi_index'],op_flags=['readwrite'])\n",
    "    \n",
    "    while not it.finished:\n",
    "        idx=it.multi_index\n",
    "        #print(\"debug3. idx= \", idx, \", x[idx] =\",x[idx])\n",
    "        \n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val) + delta_x\n",
    "        fx1 = f(x) # f(x+delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val - delta_x\n",
    "        fx2 = f(x) # f(x-delta_x)\n",
    "        grad[idx] = (fx1 - fx2) / (2*delta_x)\n",
    "        \n",
    "        #print(\"debug4. grad[idx] =\",grad[idx])\n",
    "        #print(\"debug5. grad =\",grad)\n",
    "        #print(\"==============================================\")\n",
    "        \n",
    "        x[idx] = tmp_val\n",
    "        it.iternext() \n",
    "        \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6db46b4c-34aa-4308-aa8c-673ceacdacc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_val(x,t):\n",
    "    y=np.dot(x,W)+b\n",
    "    return (np.sum((t-y)**2))/(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4d1cd7c4-912e-4148-9f86-03c72242e522",
   "metadata": {},
   "outputs": [],
   "source": [
    "#학습을 마친 후, 임의 데이터에 대해 미래 값 예측 함수\n",
    "def predict(x):\n",
    "    y=np.dot(x,W)+b\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "68d17d91-ee25-48ff-b029-2898bc3d808b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial error value= 4.634883721011157 Initial W= [[0.58023341]] \n",
      " ,b= [71.62788369]\n",
      "step= 0 , error value= 4.634883721011117 , W= [[0.58023341]] , b= [71.6278837]\n",
      "step= 500 , error value= 4.634883720990236 , W= [[0.58023329]] , b= [71.62788693]\n",
      "step= 1000 , error value= 4.634883720974734 , W= [[0.58023319]] , b= [71.62788971]\n",
      "step= 1500 , error value= 4.634883720963247 , W= [[0.5802331]] , b= [71.62789211]\n",
      "step= 2000 , error value= 4.634883720954703 , W= [[0.58023303]] , b= [71.62789417]\n",
      "step= 2500 , error value= 4.634883720948386 , W= [[0.58023296]] , b= [71.62789595]\n",
      "step= 3000 , error value= 4.63488372094371 , W= [[0.5802329]] , b= [71.62789748]\n",
      "step= 3500 , error value= 4.634883720940237 , W= [[0.58023286]] , b= [71.6278988]\n",
      "step= 4000 , error value= 4.6348837209376565 , W= [[0.58023282]] , b= [71.62789993]\n",
      "step= 4500 , error value= 4.634883720935732 , W= [[0.58023278]] , b= [71.62790091]\n",
      "step= 5000 , error value= 4.634883720934303 , W= [[0.58023275]] , b= [71.62790175]\n",
      "step= 5500 , error value= 4.634883720933254 , W= [[0.58023272]] , b= [71.62790248]\n",
      "step= 6000 , error value= 4.634883720932492 , W= [[0.5802327]] , b= [71.6279031]\n",
      "step= 6500 , error value= 4.6348837209318825 , W= [[0.58023268]] , b= [71.62790364]\n",
      "step= 7000 , error value= 4.63488372093148 , W= [[0.58023266]] , b= [71.6279041]\n",
      "step= 7500 , error value= 4.634883720931151 , W= [[0.58023265]] , b= [71.6279045]\n",
      "step= 8000 , error value= 4.634883720930914 , W= [[0.58023264]] , b= [71.62790484]\n",
      "step= 8500 , error value= 4.634883720930731 , W= [[0.58023263]] , b= [71.62790514]\n",
      "step= 9000 , error value= 4.6348837209306035 , W= [[0.58023262]] , b= [71.6279054]\n",
      "step= 9500 , error value= 4.634883720930523 , W= [[0.58023261]] , b= [71.62790561]\n",
      "step= 10000 , error value= 4.634883720930436 , W= [[0.5802326]] , b= [71.6279058]\n",
      "step= 10500 , error value= 4.63488372093038 , W= [[0.58023259]] , b= [71.62790597]\n",
      "step= 11000 , error value= 4.634883720930348 , W= [[0.58023259]] , b= [71.62790611]\n",
      "step= 11500 , error value= 4.6348837209303335 , W= [[0.58023259]] , b= [71.62790623]\n",
      "step= 12000 , error value= 4.63488372093031 , W= [[0.58023258]] , b= [71.62790633]\n",
      "step= 12500 , error value= 4.6348837209302705 , W= [[0.58023258]] , b= [71.62790642]\n",
      "step= 13000 , error value= 4.634883720930275 , W= [[0.58023258]] , b= [71.6279065]\n",
      "step= 13500 , error value= 4.634883720930251 , W= [[0.58023257]] , b= [71.62790656]\n",
      "step= 14000 , error value= 4.6348837209302545 , W= [[0.58023257]] , b= [71.62790662]\n",
      "step= 14500 , error value= 4.63488372093026 , W= [[0.58023257]] , b= [71.62790667]\n",
      "step= 15000 , error value= 4.63488372093025 , W= [[0.58023257]] , b= [71.62790671]\n",
      "step= 15500 , error value= 4.634883720930232 , W= [[0.58023257]] , b= [71.62790675]\n",
      "step= 16000 , error value= 4.6348837209302465 , W= [[0.58023257]] , b= [71.62790678]\n",
      "step= 16500 , error value= 4.634883720930242 , W= [[0.58023256]] , b= [71.62790681]\n",
      "step= 17000 , error value= 4.634883720930232 , W= [[0.58023256]] , b= [71.62790683]\n",
      "step= 17500 , error value= 4.63488372093023 , W= [[0.58023256]] , b= [71.62790685]\n",
      "step= 18000 , error value= 4.63488372093023 , W= [[0.58023256]] , b= [71.62790687]\n",
      "step= 18500 , error value= 4.634883720930247 , W= [[0.58023256]] , b= [71.62790688]\n",
      "step= 19000 , error value= 4.634883720930236 , W= [[0.58023256]] , b= [71.6279069]\n",
      "step= 19500 , error value= 4.634883720930226 , W= [[0.58023256]] , b= [71.62790691]\n",
      "step= 20000 , error value= 4.634883720930241 , W= [[0.58023256]] , b= [71.62790692]\n",
      "step= 20500 , error value= 4.634883720930238 , W= [[0.58023256]] , b= [71.62790693]\n",
      "step= 21000 , error value= 4.6348837209302305 , W= [[0.58023256]] , b= [71.62790693]\n",
      "step= 21500 , error value= 4.634883720930238 , W= [[0.58023256]] , b= [71.62790694]\n",
      "step= 22000 , error value= 4.634883720930228 , W= [[0.58023256]] , b= [71.62790694]\n",
      "step= 22500 , error value= 4.63488372093022 , W= [[0.58023256]] , b= [71.62790695]\n",
      "step= 23000 , error value= 4.6348837209302465 , W= [[0.58023256]] , b= [71.62790695]\n",
      "step= 23500 , error value= 4.634883720930236 , W= [[0.58023256]] , b= [71.62790696]\n",
      "step= 24000 , error value= 4.63488372093024 , W= [[0.58023256]] , b= [71.62790696]\n",
      "step= 24500 , error value= 4.634883720930228 , W= [[0.58023256]] , b= [71.62790696]\n",
      "step= 25000 , error value= 4.634883720930236 , W= [[0.58023256]] , b= [71.62790696]\n",
      "step= 25500 , error value= 4.6348837209302305 , W= [[0.58023256]] , b= [71.62790697]\n",
      "step= 26000 , error value= 4.634883720930227 , W= [[0.58023256]] , b= [71.62790697]\n",
      "step= 26500 , error value= 4.634883720930238 , W= [[0.58023256]] , b= [71.62790697]\n",
      "step= 27000 , error value= 4.634883720930225 , W= [[0.58023256]] , b= [71.62790697]\n",
      "step= 27500 , error value= 4.63488372093023 , W= [[0.58023256]] , b= [71.62790697]\n",
      "step= 28000 , error value= 4.634883720930228 , W= [[0.58023256]] , b= [71.62790697]\n",
      "step= 28500 , error value= 4.634883720930238 , W= [[0.58023256]] , b= [71.62790697]\n",
      "step= 29000 , error value= 4.634883720930246 , W= [[0.58023256]] , b= [71.62790697]\n",
      "step= 29500 , error value= 4.63488372093023 , W= [[0.58023256]] , b= [71.62790697]\n",
      "step= 30000 , error value= 4.6348837209302465 , W= [[0.58023256]] , b= [71.62790697]\n"
     ]
    }
   ],
   "source": [
    "#learning_rate=1e-2 #발산하는 경우, 1e-3 ~ 1e-6 등으로 바꿔서 실행\n",
    "learning_rate=1e-3\n",
    "\n",
    "f=lambda x : loss_func(x_data,t_data) #f(x)=loss_funcs(x_data,t_data)\n",
    "\n",
    "print('Initial error value=',error_val(x_data,t_data),'Initial W=',W,'\\n',',b=',b)\n",
    "\n",
    "for step in range(30001):\n",
    "    W-=learning_rate*numerical_derivative(f,W)\n",
    "    b-=learning_rate*numerical_derivative(f,b)\n",
    "    \n",
    "    if(step%500==0):\n",
    "        print('step=',step,', error value=',error_val(x_data,t_data),', W=',W,', b=',b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "35cad10b-2b74-46e4-beff-85093e7b8653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[89.03488372]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
