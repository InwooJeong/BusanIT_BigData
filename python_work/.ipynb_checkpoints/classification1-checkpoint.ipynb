{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bef3e8b-a285-4809-8de8-25f15433eb25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data.shape= (10, 1) , t_data.shape= (10, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_data=np.array([2,4,6,8,10,12,14,16,18,20]).reshape(10,1)\n",
    "t_data=np.array([0,0,0,0,0,0,1,1,1,1]).reshape(10,1)\n",
    "\n",
    "print('x_data.shape=',x_data.shape,', t_data.shape=',t_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a88e5c3-377a-40d5-8945-0077d0ad9ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W= [[0.55276552]] ,W.shape= (1, 1) ,b= [0.2973738] ,b.shape= (1,)\n"
     ]
    }
   ],
   "source": [
    "W=np.random.rand(1,1)\n",
    "b=np.random.rand(1)\n",
    "print('W=',W,',W.shape=',W.shape,',b=',b,',b.shape=',b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b80ce065-cb72-4930-860e-abb30f9efa6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#최종출력은 y=sigmoind(Wx+b)이며, 손실함수는 cross=entropy로 나타냄\n",
    "\n",
    "def sigmoid(x):\n",
    "    return1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "315eedf0-819b-44c5-a453-edf234eb5624",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(x,t):\n",
    "    \n",
    "    delta=1e-7 #log 무한대 발산 방지\n",
    "    \n",
    "    z=np.dot(x,W)+b #y=Wx+b\n",
    "    y=sigmoid(z)\n",
    "    \n",
    "    return -np.sum(t*np.log(y+delta)+(1-t)*np.log((1-y)+delta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7551dbd-df86-47d3-9417-85fcf1ca0159",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_derivative(f,x):\n",
    "    delta_x=1e-4\n",
    "    grad=np.zeros_like(x)\n",
    "    #print(\"debug1. initial input variable =\",x)\n",
    "    #print(\"debug2. initial grad =\",grad)\n",
    "    #print(\"==============================================\")\n",
    "    \n",
    "    it=np.nditer(x,flags=['multi_index'],op_flags=['readwrite'])\n",
    "    \n",
    "    while not it.finished:\n",
    "        idx=it.multi_index\n",
    "        #print(\"debug3. idx= \", idx, \", x[idx] =\",x[idx])\n",
    "        \n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val) + delta_x\n",
    "        fx1 = f(x) # f(x+delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val - delta_x\n",
    "        fx2 = f(x) # f(x-delta_x)\n",
    "        grad[idx] = (fx1 - fx2) / (2*delta_x)\n",
    "        \n",
    "        #print(\"debug4. grad[idx] =\",grad[idx])\n",
    "        #print(\"debug5. grad =\",grad)\n",
    "        #print(\"==============================================\")\n",
    "        \n",
    "        x[idx] = tmp_val\n",
    "        it.iternext() \n",
    "        \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1fa99d35-7d36-4fee-9c5b-3d0f81a37609",
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_val(x,t):\n",
    "    delta=1e-7 #log 무한대 발산 방지\n",
    "    \n",
    "    z=np.dot(x,W)+b #y=Wx+b\n",
    "    y=sigmoid(z)\n",
    "    \n",
    "    #cross-entropy\n",
    "    return -np.sum(t*np.log(y+delta)+(1-t)*np.log((1-y)+delta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c0f6fc-22ea-4625-b9cf-7de45cadfad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#학습을 마친 후, 임의 데이터에 대한 미래 값 예측 함수\n",
    "#입력변수 x:numpy type\n",
    "def predict(x):\n",
    "    z=np.dot(x,W)+b\n",
    "    y=sigmoid(z)\n",
    "    \n",
    "    if y>0.5:\n",
    "        result=1 #True\n",
    "    else:\n",
    "        result=0 #False\n",
    "        \n",
    "    return y, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f31bdd5-3a98-494b-b09b-749b5188422d",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=1e-2 #발산하는 경우 1e-3 ~ 1e-6 등으로 바꿔서 실행\n",
    "\n",
    "f=lambda x : loss_func(x_data,t_data) #f(x)=loss_funcs(x_data,t_data)\n",
    "\n",
    "print('Initial error value=',error_val(x_data,t_data),'Initial W=',W,'\\n',',b=',b)\n",
    "\n",
    "for step in range(20001):\n",
    "    W-=learning_rate*numerical_derivative(f,W)\n",
    "    b-=learning_rate*numerical_derivative(f,b)\n",
    "    \n",
    "    if(step%400==0):\n",
    "        print('step=',step,', error value=',error_val(x_data,t_data),', W=',W,', b=',b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
